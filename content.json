{"meta":{"title":"LearningSpace","subtitle":"leveysama","description":"springcloud dubbo","author":"LeveySama","url":"http://stomachache.vip","root":"/"},"pages":[],"posts":[{"title":"一次线上JVM调优","slug":"jvm","date":"2019-07-29T14:12:16.000Z","updated":"2020-03-25T16:59:56.000Z","comments":true,"path":"learn/jvm/","link":"","permalink":"http://stomachache.vip/learn/jvm/","excerpt":"","text":"一次临时大流量涌入的时候，线上系统监控发生了报警，观察JVM监控统计发现Old区GC时间过长达到10秒以上。 我们平台系统有如下特点： 每台机器要支持海量连接，超过10w qps相当高，新生代迅速增长 综上特点会导致有大量对象会转移至old区，高峰期old区域增长非常快，但是对象在一段时间内肯定会消亡。 jvm参数如下 12345-Xms8g -Xmx8g -Xss512k -XX:PermSize&#x3D;256m -XX:MaxPermSize&#x3D;256m -XX:NewSize&#x3D;5g -XX:MaxNewSize&#x3D;5g-XX:SurvivorRatio&#x3D;8 -XX:MaxDirectMemorySize&#x3D;4g -XX:+UseParNewGC -XX:ParallelGCThreads&#x3D;4-XX:MaxTenuringThreshold&#x3D;6 -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly-XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:CMSFullGCsBeforeCompaction&#x3D;9 第一眼看见对象年龄竟然只设置了6，那就意味着eden区进入到old区的速度也太快了，很容易触发old gc，我知道这个系统所使用的对象在一一段时间内一定会消亡，尝试第一次调整： 将年龄调成最大值15，再调大young区 1234567-Xms12g -Xmx12g -Xss512k -XX:PermSize&#x3D;256m -XX:MaxPermSize&#x3D;256m -XX:NewSize&#x3D;10g -XX:MaxNewSize&#x3D;10g -XX:SurvivorRatio&#x3D;18 -XX:MaxDirectMemorySize&#x3D;2g -XX:+UseParNewGC -XX:ParallelGCThreads&#x3D;4 -XX:MaxTenuringThreshold&#x3D;15 -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction&#x3D;15 -XX:CMSInitiatingOccupancyFraction&#x3D;70 -XX:+CMSClassUnloadingEnabled -XX:SoftRefLRUPolicyMSPerMB&#x3D;0 -XX:-ReduceInitialCardMarks -XX:+CMSPermGenSweepingEnabled -XX:CMSInitiatingPermOccupancyFraction&#x3D;70 Old gc频率果然下降了，但是每次清理时长没有明显差别，继续第二次调整： 鉴于之前cms收集器在old gc上花的时间比较多，尝试换成了serial old看看效果 123-Xms12g -Xmx12g -Xss512k -XX:PermSize&#x3D;256m -XX:MaxPermSize&#x3D;256m -XX:NewSize&#x3D;10g -XX:MaxNewSize&#x3D;10g -XX:SurvivorRatio&#x3D;18 -XX:MaxDirectMemorySize&#x3D;2g -XX:+UseParNewGC -XX:ParallelGCThreads&#x3D;4 -XX:MaxTenuringThreshold&#x3D;15 发现效果确实比较明显，old gc的时间从原来的10000ms+ 缩短到了2000ms以内. 后来翻阅了jvm资料，学习了一下CMS垃圾收集的原理，它有两个阶段会发生STW，一个是初始化标记（intial mark），一个是重复标记（cms remark)，重复标记的原因是前一阶段是并行的，也就是业务线程和GC线程同时运作，那么在前一阶段的时间内一开始被标记的很多对象的状态可能都已经产生了变化，所以这个时候需要进入安全点停止所有用户线程，再来一次标记再清除。然后特地查看了下GC日志，发现remark时间很长。 1[1 CMS-remark: 2202742K(3145728K)] 6959670K(9751808K), 18.1769610 secs] [Times: user&#x3D;71.37 sys&#x3D;0.06, real&#x3D;18.18 secs] 突然想到我eden区设置的很大，高峰期的时候，一次cms old开始，到remark之间这段时间，用户程序会和gc线程同步执行，到remark的时候，eden区很可能已经有大量对象了同时很多对象的状态已经被改变，那如果remark之前能把eden区域的对象先清理一遍，那么就降低了remark的负担了吧？？？？翻书发现-XX:+CMSScavengeBeforeRemark，这个参数的意思是在remark之前，先进行一次YGC，迫不及待带的加了这个参数验证我的猜想。 12345-Xms12g -Xmx12g -Xss512k -XX:PermSize&#x3D;256m -XX:MaxPermSize&#x3D;256m -XX:NewSize&#x3D;10g -XX:MaxNewSize&#x3D;10g -XX:SurvivorRatio&#x3D;18 -XX:MaxDirectMemorySize&#x3D;2g -XX:+UseParNewGC -XX:ParallelGCThreads&#x3D;4 -XX:MaxTenuringThreshold&#x3D;15 -XX:+CMSScavengeBeforeRemark -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction&#x3D;9 -XX:CMSInitiatingOccupancyFraction&#x3D;70 监控统计发现old gc的时间缩小到了0.14s！可以证实我的猜测是对的，在这样的高并发系统中同时对象又在一定时间会消亡的情况下，在CMS REMARK之前先来一次YGC可以大幅的降低REMARK的负担。","categories":[],"tags":[]},{"title":"Netty入门学习","slug":"netty01","date":"2019-07-18T08:32:26.000Z","updated":"2020-03-25T15:31:54.000Z","comments":true,"path":"learn/netty01/","link":"","permalink":"http://stomachache.vip/learn/netty01/","excerpt":"","text":"服务端启动代码12345678910111213141516171819202122232425262728293031323334353637383940414243public final class SimpleServer &#123; public static void main(String[] args) throws Exception &#123; EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .handler(new SimpleServerHandler()) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; &#125; &#125;); ChannelFuture f = b.bind(80).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125; private static class SimpleServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelActive\"); &#125; @Override public void channelRegistered(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"channelRegistered\"); &#125; @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(\"handlerAdded\"); &#125; &#125;&#125; Netty组件认识1、Bootstrap引导类负责引导Netty，设置参数配置。引导过程包括启动线程、打开套接字等。 2、EventLoopGroupEventLoopGroup是EventLoop组。负责管理EventLoop，通过轮询方式分配一个EventLoop。 3、EventLoopEventLoop是一个不断寻找新事件的任务，例如来自网络套接字(来自SocketChannel)实例的传入数据。当事件发生时，事件被传递给适当的事件处理程序，例如ChannelHandler。 4、SocketChannelSocketChannel表示通过网络连接到另一台计算机的TCP连接。无论使用Netty作为客户机还是服务器，与网络上其他计算机交换的所有数据都通过一个SocketChannel实例传递，该实例表示计算机之间的TCP连接。 SocektChannel由一个EventLoop管理，并且始终只由同一个EventLoop管理。因为EventLoop总是由同一个线程执行，所以SocketChannel实例也只能由同一个线程访问。因此，在从套接字通道读取数据时，不必担心同步问题。 5、ChannelInitializerNetty通道初始化器是一种特殊的通道处理程序，它在创建SocketChannel时附加到SocketChannel的ChannelPipeline上。然后调用ChannelInitializer，以便它可以初始化SocketChannel。 在初始化SocketChannel之后，ChannelInitializer将自己从ChannelPipeline中移除。 6、ChannelPipeLine每个Netty套接字通道都有一个通道管道。ChannelPipeline包含ChannelHandler实例的列表。当EventLoop从SocketChannel读取数据时，数据被传递给ChannelPipeline中的第一个ChannelHandler。第一个ChannelHandler处理数据，可以选择将数据转发给ChannelPipeline中的下一个ChannelHandler，下一个ChannelHandler也处理数据，可以选择将数据转发给ChannelPipeline中的下一个ChannelHandler等。 当将数据写入SocketChannel时，写入的数据在最终写入SocketChannel之前也会通过ChannelPipeline传递。 7、ChannelHandlerChannelHandler处理从Netty SocketChannel接收的数据。ChannelHandler还可以处理被写入SocketChannel的数据。","categories":[],"tags":[]},{"title":"NIO多路复用学习笔记","slug":"nio","date":"2019-07-13T12:46:25.000Z","updated":"2020-03-25T14:41:02.000Z","comments":true,"path":"learn/nio/","link":"","permalink":"http://stomachache.vip/learn/nio/","excerpt":"","text":"I/O多路复用技术在I/O编程过程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者I/O多路复用技术进行处理。I/O多路复用技术通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型相比，I/O多路复用技术的最大优势是系统开销小，系统不需要创建新的额外进程或线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源，I/O多路复用的主要应用场景如下： 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字；服务器需要同时处理多种网络协议的套接字；目前支持I/O多路复用的系统调用有select、pselect、 poll、epoll，在Linux网络编程过程中，很长一段时间都使用select做轮询和网络事件通知，然而select的一些固有缺陷导致了它的应用受到了很大的限制，最终Linux不得不在新的内核版本中寻找select的替代方案，最终选择了epoll。epoll与select的原理比较类似，为了克服select的缺点，epoll做了很多重大改进，总结如下： 支持一个进程打开的socket描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）。I/O效率不会随着FD数量的增加而线性下降。传统select/poll的另一个致命弱点，就是当你拥有一个很大的socket集合时，由于网络延时或者链路空闲，任意时刻只有少部分的socket是“活跃”的，但是select/poll每次调用都会线性扫描全部的集合，导致效率呈线性下降。epoll不存在这个问题，它只会对“活跃”的socket进行操作——这是因为在内核的实现中，epoll是根据每个fd上面的callback函数实现的。那么只有“活跃”的socket才会去主动调用callback函数，其他idle状态的socket则不会。在这点上，epoll实现了一个伪AIO。使用mmap加速内核与用户空间的消息传递。epoll的API更加简单。Java I/O演进之路从JDK1.0到JDK1.3，Java I/O类库都非常原始，很多UNIX网络编程中的概念或者接口在I/O类库中都没有体现，例如Pipe、Channel、Buffer和Selector等。在2002年发布JDK1.4时，NIO以JSR-51的身份正式随JDK发布。它新增了java.nio包，提供了很多进行异步I/O开发的API和类库，主要的类和接口如下： 进行异步I/O操作的缓冲区ByteBuffer等； 进行异步I/O操作的管道Pipe； 进行各种I/O操作的（同步或异步）的Chanel，包括ServerSocketChanel和SocketChanel； 多种字符集的编码能力和解码能力； 实现非阻塞I/O操作的多路复用器Selector； 文件通道FileChanel； 新的NIO类库的提供，极大的促进了基于Java的异步非阻塞编程的应用和发展，但是，它依然有不完善的地方，特别是对文件系统的处理能力仍显不足，主要问题如下： 没有统一的文件属性（例如读写权限）；API能力较弱，例如目录的级联创建和递归遍历，往往需要自己实现；底层存储系统的一些高级API无法使用；所有的文件操作都是同步阻塞调用，不支持异步文件读写操作。2011年7月28日，JDK7正式发布。它的一个比较大的亮点就是将原来的NIO类库进行了升级，被称为NIO 2.0。NIO 2.0由JSR-203演进而来，它主要提供了如下三个方面的改进： 提供能够批量获取文件属性的API，这些API具有平台无关性，不与特定的文件系统相耦合。另外，它还提供了标准文件的SPI，供各个服务提供商扩展实现；提供AIO功能，支持基于文件的异步I/O操作和针对网络套接字的异步操作；完成JSR-51定义的通道功能，包括对配置和多播的数据报的支持等。","categories":[],"tags":[]}],"categories":[],"tags":[]}